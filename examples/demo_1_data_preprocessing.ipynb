{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6396cc9a-e45c-4e92-be90-d8c7698d6674",
   "metadata": {},
   "source": [
    "# ATEK Demo 1: ATEK data preprocessing + model inference\n",
    "\n",
    "This demo will walk through the steps of preparing an Aria data sequence with annotations ([AriaDigitalTwin (ADT)](https://www.projectaria.com/datasets/adt/)), for use in a 3D object detection model CubeRCNN, run model inference on the preprocessed data, and evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a034b-7464-419a-b0df-211019f09c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.data_preprocess.genera_atek_preprocessor_factory import (\n",
    "    create_general_atek_preprocessor_from_conf,\n",
    ")\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_preprocess.general_atek_preprocessor import GeneralAtekPreprocessor\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.data_preprocess.atek_data_sample import (\n",
    "    create_atek_data_sample_from_flatten_dict,\n",
    ")\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone  # noqa\n",
    "from cubercnn.modeling.meta_arch import build_model  # noqa\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Prettier colors\n",
    "COLOR_GREEN = [42,157,143]\n",
    "COLOR_RED = [231, 111, 81]\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def print_data_sample_dict_content(data_sample, if_pretty: bool = False):\n",
    "    \"\"\"\n",
    "    A helper function to print the content of data sample dict\n",
    "    \"\"\"\n",
    "    logger.info(\"Printing the content in a ATEK data sample dict: \")\n",
    "    for key, val in data_sample.items():\n",
    "        if if_pretty and \"#\" in key:\n",
    "            key = key.split(\"#\", 1)[1]\n",
    "        \n",
    "        msg = f\"\\t {key}: is a {type(val)}, \"\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            msg += f\"with shape of : {val.shape}\"\n",
    "        elif isinstance(val, list):\n",
    "            msg += f\"with len of : {len(val)}\"\n",
    "        elif isinstance(val, str):\n",
    "            msg += f\"value is {val}\"\n",
    "        else:\n",
    "            pass\n",
    "        logger.info(msg)\n",
    "\n",
    "def create_inference_model(config_file, ckpt_dir, use_cpu_only=False):\n",
    "    \"\"\"\n",
    "    Create the model for inference pipeline, with the model config.\n",
    "    \"\"\"\n",
    "    # Create default model configuration\n",
    "    model_config = get_cfg()\n",
    "    get_cfg_defaults(model_config)\n",
    "\n",
    "    # add extra configs for data\n",
    "    model_config.MAX_TRAINING_ATTEMPTS = 3\n",
    "    model_config.TRAIN_LIST = \"\"\n",
    "    model_config.TEST_LIST = \"\"\n",
    "    model_config.TRAIN_WDS_DIR = \"\"\n",
    "    model_config.TEST_WDS_DIR = \"\"\n",
    "    model_config.ID_MAP_JSON = \"\"\n",
    "    model_config.OBJ_PROP_JSON = \"\"\n",
    "    model_config.CATEGORY_JSON = \"\"\n",
    "    model_config.DATASETS.OBJECT_DETECTION_MODE = \"\"\n",
    "    model_config.SOLVER.VAL_MAX_ITER = 0\n",
    "    model_config.SOLVER.MAX_EPOCH = 0\n",
    "\n",
    "    model_config.merge_from_file(config_file)\n",
    "    if use_cpu_only:\n",
    "        model_config.MODEL.DEVICE = \"cpu\"\n",
    "    model_config.freeze()\n",
    "\n",
    "    model = build_model(model_config, priors=None)\n",
    "\n",
    "    _ = DetectionCheckpointer(model, save_dir=ckpt_dir).resume_or_load(\n",
    "        model_config.MODEL.WEIGHTS, resume=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    return model_config, model\n",
    "\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    \n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589bfd9-b5dd-405a-bcbc-611f799a84ad",
   "metadata": {},
   "source": [
    "## Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e3c80-f8bb-4a0b-a7af-c293fb49edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the following guide to download example ADT sequence to a local path `~/Documents/projectaria_tools_adt_data`\n",
    "# https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download.\n",
    "\n",
    "# Set up local data paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data\")\n",
    "sequence_name = \"Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "example_adt_data_dir = os.path.join(data_dir, sequence_name)\n",
    "output_wds_path = os.path.join(data_dir, \"wds_output\")\n",
    "\n",
    "# Set up ATEK paths\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "atek_preprocess_config_path = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/adt_cubercnn_preprocess_config.yaml\"\n",
    "category_mapping_file = os.path.join(atek_src_path, \"data\", \"adt_prototype_to_atek.csv\")\n",
    "preprocess_conf = OmegaConf.load(atek_preprocess_config_path)\n",
    "\n",
    "# Set up trained model weight path\n",
    "model_ckpt_path = \"/home/louy/Calibration_data_link/Atek/pre_trained_models/2024_08_28_AdtCubercnnWeights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc535e11-2994-4ba6-b93e-11d922ccd3aa",
   "metadata": {},
   "source": [
    "# Step 1: ATEK data preprocessing\n",
    "In this example, we demonstrate how to preprocess Aria data sequences for ML training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e893b-62d0-4dac-8e7c-9a00a598eb88",
   "metadata": {},
   "source": [
    "### Set up and run ATEK data preprocessor\n",
    "Common data required for 3D object detection models: \n",
    "* camera image.\n",
    "* bounding box annotations (3D, maybe + 2D)\n",
    "* camera models + pose info.\n",
    "\n",
    "Typical preprocessing needed: \n",
    "* Data synchronization. \n",
    "* Image rotation.\n",
    "* Undistort to linear camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d627af5-9b3d-408e-80bf-ca062b9ed47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ATEK preprocessor from conf. It will automatically choose which type of sample to build.\n",
    "atek_preprocessor = create_general_atek_preprocessor_from_conf(\n",
    "    # [required]\n",
    "    conf=preprocess_conf,  \n",
    "    raw_data_folder = example_adt_data_dir,   \n",
    "    sequence_name = sequence_name, \n",
    "    # [optional]\n",
    "    output_wds_folder=output_wds_path, \n",
    "    output_viz_file=os.path.join(example_adt_data_dir, \"atek_preprocess_viz.rrd\"),\n",
    "    category_mapping_file=category_mapping_file,\n",
    ")\n",
    "\n",
    "# Loop over all samples, and write valid ones to local tar files.\n",
    "atek_preprocessor.process_all_samples(write_to_wds_flag=True, viz_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27367d2a",
   "metadata": {},
   "source": [
    "## Inspecting content in the preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f2614-12e0-4a75-b9df-000f1cc1e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_command = [\"ls\", f\"{output_wds_path}\"]\n",
    "return_code = run_command_and_display_output(listing_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33a140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspect_command = [\"tar\", \"tvf\", f\"{output_wds_path}/shards-0000.tar\"]\n",
    "return_code = run_command_and_display_output(inspect_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999a355-3429-4883-a890-65cf00819a24",
   "metadata": {},
   "source": [
    "# Step 2: Run Object detection inference using pre-trained CubeRCNN model\n",
    "In this example, we demonstrate how to run model inference with preprocessed ATEK data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b83d9a-61f7-4dce-bfe3-90c28f9ce0b1",
   "metadata": {},
   "source": [
    "### Create a PyTorch DataLoader from ATEK WDS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9920b-9ac7-441c-8857-fd454d0dd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ATEK dataloader with native ATEK format.\n",
    "tar_file_urls = [os.path.join(output_wds_path, f\"shards-000{i}.tar\") for i in range(2)]\n",
    "\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size = None, num_workers = 1)\n",
    "first_atek_sample = next(iter(atek_dataloader)) \n",
    "logger.info(f\"Loading WDS into ATEK natvie format, each sample contains the following keys: {first_atek_sample.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be78458-be2f-45f4-929d-53c7e7c76305",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader, converted to CubeRCNN format\n",
    "The `create_atek_dataloader_as_cubercnn` API is a thin wrapper on top of a `CubeRCNN` data converter class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e554e4-e417-439d-8f28-270f2dc864e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 6, num_workers = 1)\n",
    "first_cubercnn_sample = next(iter(cubercnn_dataloader)) \n",
    "logger.info(f\"Loading WDS into CubeRCNN format, each sample contains the following keys: {first_cubercnn_sample[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb49da-26f9-4f31-bc2d-26ccd0f1c755",
   "metadata": {},
   "source": [
    "## Run model inference over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a77b73-3307-4e44-bbe4-314859634a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load pre-trained CubeRCNN model\n",
    "model_config_file = os.path.join(model_ckpt_path, \"config.yaml\")\n",
    "conf = OmegaConf.load(model_config_file)\n",
    "\n",
    "# setup config and model\n",
    "model_config, model = create_inference_model(\n",
    "    model_config_file, model_ckpt_path, False\n",
    ")\n",
    "\n",
    "\n",
    "# Cache inference results for visualization\n",
    "input_output_data_pairs = []\n",
    "\n",
    "# Loop over created Pytorch Dataloader\n",
    "with torch.no_grad():\n",
    "    for cubercnn_input_data in tqdm(\n",
    "       cubercnn_dataloader,\n",
    "        desc=\"Inference progress: \",\n",
    "    ):\n",
    "        cubercnn_model_output = model(cubercnn_input_data)\n",
    "\n",
    "        # cache inference results for visualization\n",
    "        input_output_data_pairs.append((cubercnn_input_data, cubercnn_model_output))\n",
    "\n",
    "logger.info(\"Inference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c358cb-54f2-4b35-8cf4-e8aee553c48a",
   "metadata": {},
   "source": [
    "### Visualize inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421f6b5-89a7-4387-984d-3f766137cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.viz.cubercnn_visualizer import CubercnnVisualizer\n",
    "\n",
    "# Visualize cached inference results\n",
    "logger.info(\"Visualizing inference results.\")\n",
    "viz_conf = preprocess_conf.visualizer\n",
    "cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", conf = viz_conf)\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        # Plot RGB image\n",
    "        cubercnn_visualizer.plot_cubercnn_img(single_cubercnn_input[\"image\"], timestamp_ns = timestamp_ns)\n",
    "\n",
    "        # Plot GT and prediction in different colors\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"] # This patch is needed for visualization\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_GREEN, suffix = \"_model_input\")\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_RED, suffix = \"_model_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300fb70-6668-449d-935a-2f8d7ac5eb3f",
   "metadata": {},
   "source": [
    "# Step 3: Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02228983-03de-4f77-a8d5-ad2971a111a2",
   "metadata": {},
   "source": [
    "### Write inference results into ATEK-format csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ede614-9d52-462f-9dda-de874c88fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "\n",
    "gt_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"gt_obbs.csv\"))\n",
    "prediction_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"prediction_obbs.csv\"))\n",
    "\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"]\n",
    "        \n",
    "        gt_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns)\n",
    "        prediction_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52c441-4ef8-4155-a34d-2cffc4f24a99",
   "metadata": {},
   "source": [
    "### Call ATEK's benchmarking script to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6849822-4055-4a18-8a3e-d56348c79531",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/benchmarking_static_object_detection.py\",\n",
    "    \"--pred-csv\", f\"{data_dir}/prediction_obbs.csv\", \n",
    "    \"--gt-csv\", f\"{data_dir}/gt_obbs.csv\", \n",
    "    \"--output-file\", f\"{data_dir}/atek_metrics.json\"\n",
    "]\n",
    "return_code = run_command_and_display_output(benchmarking_command)"
   ]
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "8cca9f3e-a062-4627-9916-8f40d129e10f",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
