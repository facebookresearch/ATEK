{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e06544-6986-46b4-8203-af24adea623e",
   "metadata": {},
   "source": [
    "# Demo 2: ATEK Data Store and Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3298eca3-0e9e-4c68-905c-24bdc08efb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.util.file_io_utils import load_yaml_and_extract_tar_list\n",
    "\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone  # noqa\n",
    "from cubercnn.modeling.meta_arch import build_model  # noqa\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n",
    "\n",
    "def create_inference_model(config_file, ckpt_dir, use_cpu_only=False):\n",
    "    \"\"\"\n",
    "    Create the model for inference pipeline, with the model config.\n",
    "    \"\"\"\n",
    "    # Create default model configuration\n",
    "    model_config = get_cfg()\n",
    "    get_cfg_defaults(model_config)\n",
    "\n",
    "    # add extra configs for data\n",
    "    model_config.MAX_TRAINING_ATTEMPTS = 3\n",
    "    model_config.TRAIN_LIST = \"\"\n",
    "    model_config.TEST_LIST = \"\"\n",
    "    model_config.TRAIN_WDS_DIR = \"\"\n",
    "    model_config.TEST_WDS_DIR = \"\"\n",
    "    model_config.ID_MAP_JSON = \"\"\n",
    "    model_config.OBJ_PROP_JSON = \"\"\n",
    "    model_config.CATEGORY_JSON = \"\"\n",
    "    model_config.DATASETS.OBJECT_DETECTION_MODE = \"\"\n",
    "    model_config.SOLVER.VAL_MAX_ITER = 0\n",
    "    model_config.SOLVER.MAX_EPOCH = 0\n",
    "\n",
    "    model_config.merge_from_file(config_file)\n",
    "    if use_cpu_only:\n",
    "        model_config.MODEL.DEVICE = \"cpu\"\n",
    "    model_config.freeze()\n",
    "\n",
    "    model = build_model(model_config, priors=None)\n",
    "\n",
    "    _ = DetectionCheckpointer(model, save_dir=ckpt_dir).resume_or_load(\n",
    "        model_config.MODEL.WEIGHTS, resume=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    return model_config, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5175170-34ca-4d55-940d-7e3c137b0f93",
   "metadata": {},
   "source": [
    "### Setup data and code path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f66dce-dc82-460a-b3bf-80cc3bd2c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun\"\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "data_store_viz_conf = OmegaConf.load(os.path.join(data_dir, \"data_store_viz_conf.yaml\"))\n",
    "infer_viz_conf = OmegaConf.load(os.path.join(data_dir, \"infer_viz_conf.yaml\"))\n",
    "\n",
    "# Set up trained model weight path\n",
    "model_ckpt_path = \"/home/louy/Calibration_data_link/Atek/pre_trained_models/2024_08_28_AdtCubercnnWeights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b2f25-2990-492c-8602-24cc4b22ae85",
   "metadata": {},
   "source": [
    "## Part 1: ATEK Data Store\n",
    "**Before ATEK**: user needs to set up their own preprocessing, and run through large datasets. **time- & resource- consuming** (14 days for 10K seqs). \n",
    "\n",
    "**With ATEK**: preprocessed Aria datasets hosted on **ATEK Data Store**:  \n",
    "1. [Option 1] Download to local.\n",
    "2. [Option 2] Stream over internet.\n",
    "\n",
    "Streaming example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74651da-9618-4801-a125-f0f0c071b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:11,262-INFO:streamable_train_tars.yaml, streamable_validation_tars.yaml, streamable_all_tars.yaml are written successfully to /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/streamable_yamls/.\n",
      "2024-09-14 22:33:11,273 - INFO - Streamable yaml files created under f/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/streamable_yamls/\n"
     ]
    }
   ],
   "source": [
    "# First, download json file from ATEK Data Store\n",
    "atek_json_path = os.path.join(data_dir, \"AriaDigitalTwin_ATEK_download_urls.json\")\n",
    "if not os.path.exists(atek_json_path):\n",
    "    logger.error(\"Please download AriaDigitalTwin_ATEK_download_urls.json from ATEK Data Store\")\n",
    "    exit()\n",
    "\n",
    "# Second, parse into streamable yaml files\n",
    "create_streamable_yaml_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/atek_wds_data_downloader.py\",\n",
    "    \"--config-name\",\"cubercnn\",\n",
    "    \"--input-json-path\",f\"{atek_json_path}\",\n",
    "    \"--output-folder-path\",f\"{data_dir}/streamable_yamls/\",\n",
    "    \"--max-num-sequences\", \"5\",\n",
    "    \"--train-val-split-ratio\", \"0.8\"\n",
    "]\n",
    "return_code = run_command_and_display_output(create_streamable_yaml_command)\n",
    "\n",
    "logger.info(f\"Streamable yaml files created under f{data_dir}/streamable_yamls/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9d4dd-62f8-46f7-a440-38ff2c12b981",
   "metadata": {},
   "source": [
    "# Part 2: Run Object detection inference using pre-trained CubeRCNN model\n",
    "In this example, we demonstrate how to run model inference with preprocessed ATEK data streamed from Data Store. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340cdd9-416a-4838-bc39-a7f879c76d8d",
   "metadata": {},
   "source": [
    "### Create a PyTorch DataLoader from ATEK WDS files\n",
    "Load WDS files as ATEK format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed5e492-e46d-4966-bd8b-12e9afc48e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louy/miniconda3/envs/atek/lib/python3.9/site-packages/webdataset/compat.py:136: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:14,663 - INFO - Loading WDS into ATEK native format, each sample contains the following keys: dict_keys(['__key__', '__url__', 'gt_data', 'mfcd#camera-rgb+camera_label', 'mfcd#camera-rgb+camera_model_name', 'mfcd#camera-rgb+capture_timestamps_ns', 'mfcd#camera-rgb+exposure_durations_s', 'mfcd#camera-rgb+frame_ids', 'mfcd#camera-rgb+gains', 'mfcd#camera-rgb+origin_camera_label', 'mfcd#camera-rgb+projection_params', 'mfcd#camera-rgb+t_device_camera', 'mtd#capture_timestamps_ns', 'mtd#gravity_in_world', 'mtd#ts_world_device', 'sequence_name', 'mfcd#camera-rgb+images'])\n"
     ]
    }
   ],
   "source": [
    "# create ATEK dataloader with native ATEK format.\n",
    "tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"streamable_yamls\", \"streamable_validation_tars.yaml\"))\n",
    "# tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"downloaded_local_wds_adt\", \"local_all_tars.yaml\"))\n",
    "\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size = None, num_workers = 1)\n",
    "first_atek_sample = next(iter(atek_dataloader))\n",
    "logger.info(f\"Loading WDS into ATEK native format, each sample contains the following keys: {first_atek_sample.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3bf24-c406-4e44-96da-ba42df3e3585",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader, converted to CubeRCNN format\n",
    "User can add a data transform function from ATEK format -> CubeRCNN format: \n",
    "1. Dict key remapping.\n",
    "2. Tensor reshaping & reordering. \n",
    "3. Other data transformations.\n",
    "\n",
    "Example data transform function for CubeRCNN model: [src code](https://www.internalfb.com/code/fbsource/[a5c3831c045bc718862d1c512e84d4ed6f79d722]/fbcode/surreal/data_services/atek/atek/data_loaders/cubercnn_model_adaptor.py?lines=44-74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0469437-9f9d-4144-b544-8e136f9048bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:20,660 - INFO - Loading WDS into CubeRCNN format, each sample contains the following keys: dict_keys(['image', 'K', 'height', 'width', 'K_matrix', 'timestamp_ns', 'frame_id', 'sequence_name', 'T_world_camera', 'instances', 'Ts_world_object', 'object_dimensions', 'category'])\n"
     ]
    }
   ],
   "source": [
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 6, num_workers = 1)\n",
    "first_cubercnn_sample = next(iter(cubercnn_dataloader))\n",
    "logger.info(f\"Loading WDS into CubeRCNN format, each sample contains the following keys: {first_cubercnn_sample[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8bfdd-2433-4169-9d42-bd0a3d6421b1",
   "metadata": {},
   "source": [
    "### Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a3408e-a181-44a5-8aee-83eb7d5e2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:39,834 - INFO - [DetectionCheckpointer] Loading from /home/louy/Calibration_data_link/Atek/pre_trained_models/2024_08_28_AdtCubercnnWeights/model_final.pth ...\n",
      "2024-09-14 22:33:39,834 - INFO - [Checkpointer] Loading from /home/louy/Calibration_data_link/Atek/pre_trained_models/2024_08_28_AdtCubercnnWeights/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference progress: : 5it [00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:44,261 - INFO - Inference completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load pre-trained CubeRCNN model\n",
    "model_config_file = os.path.join(model_ckpt_path, \"config.yaml\")\n",
    "conf = OmegaConf.load(model_config_file)\n",
    "\n",
    "# setup config and model\n",
    "model_config, model = create_inference_model(\n",
    "    model_config_file, model_ckpt_path, False\n",
    ")\n",
    "\n",
    "\n",
    "# Cache inference results for visualization\n",
    "input_output_data_pairs = []\n",
    "\n",
    "# Loop over created Pytorch Dataloader, only 5 batches for demonstration\n",
    "with torch.no_grad():\n",
    "    for cubercnn_input_data in tqdm(\n",
    "       islice(cubercnn_dataloader, 5),\n",
    "        desc=\"Inference progress: \",\n",
    "    ):\n",
    "        cubercnn_model_output = model(cubercnn_input_data)\n",
    "\n",
    "        # cache inference results for visualization\n",
    "        input_output_data_pairs.append((cubercnn_input_data, cubercnn_model_output))\n",
    "\n",
    "logger.info(\"Inference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3da8d-092f-4432-85f5-2ebb25db8559",
   "metadata": {},
   "source": [
    "### Visualize inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4165f605-ee3d-4c7d-a885-794c4a18fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:33:47,250 - INFO - Visualizing inference results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-15T05:33:47Z INFO  re_sdk::spawn] A process is already listening at this address. Assuming it's a Rerun Viewer. addr=0.0.0.0:9876\n"
     ]
    }
   ],
   "source": [
    "from atek.viz.cubercnn_visualizer import CubercnnVisualizer\n",
    "\n",
    "# Visualize cached inference results\n",
    "logger.info(\"Visualizing inference results.\")\n",
    "cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", conf = infer_viz_conf)\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        # Plot RGB image\n",
    "        cubercnn_visualizer.plot_cubercnn_img(single_cubercnn_input[\"image\"], timestamp_ns = timestamp_ns)\n",
    "\n",
    "        # Plot GT and prediction in different colors\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"] # This patch is needed for visualization\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_GREEN, suffix = \"_model_input\")\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_RED, suffix = \"_model_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e08ed-6e17-4a3e-9de2-a7c9e0571633",
   "metadata": {},
   "source": [
    "## Part 3: Evaluate model performance\n",
    "ATEK provides **per-task**: \n",
    "1. Standardized prediction file formats.\n",
    "2. Lib for common eval metrics.\n",
    "3. Benchmarking scripts.\n",
    "\n",
    "Example prediction file format for 3D object detection: \n",
    "\n",
    "| time_ns       | tx_world_object | ty_world_object | tz_world_object | qw_world_object | qx_world_object | qy_world_object | qz_world_object | scale_x | scale_y | scale_z | name    | instance | sem_id | prob    |\n",
    "|---------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|---------|---------|---------|---------|----------|--------|--------|\n",
    "| 14588033546600| -4.119894       | 0.986124        | 2.796770        | 0.008052        | -0.022706       | -0.010150       | 0.999658        | 0.190   | 2.146   | 0.900   | door    | -1       | 32     | 0.994462|\n",
    "| 14588033546600| -3.875954       | 0.837941        | 4.056602        | 0.009215        | -0.015670       | 0.999661        | -0.018645       | 0.325   | 1.697   | 0.964   | display | -1       | 37     | 0.994381|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b614c6-39b1-4bdc-af18-ed9c6ec368f2",
   "metadata": {},
   "source": [
    "### Write inference results into ATEK-format csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7dd3fd5-f1ba-413b-a8d8-4b63b09f84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:34:16,686 - INFO - starting writing obb3 to /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/gt_obbs.csv\n",
      "2024-09-14 22:34:16,688 - INFO - starting writing obb3 to /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/prediction_obbs.csv\n"
     ]
    }
   ],
   "source": [
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "\n",
    "gt_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"gt_obbs.csv\"))\n",
    "prediction_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"prediction_obbs.csv\"))\n",
    "\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"]\n",
    "\n",
    "        gt_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns)\n",
    "        prediction_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d11e34-6886-4ad4-b1fc-76d6ee540095",
   "metadata": {},
   "source": [
    "### Call ATEK's benchmarking script to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dcc6d3-1e24-473f-a231-35136623b441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 22:34:20,934-INFO:Running file-level eval on /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/prediction_obbs.csv and /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/gt_obbs.csv\n",
      "2024-09-14 22:34:20,934-INFO:starting loading evaluation obb3s from /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/prediction_obbs.csv\n",
      "2024-09-14 22:34:21,255-INFO:starting loading evaluation obb3s from /home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/gt_obbs.csv\n",
      "2024-09-14 22:34:22,580-INFO:Computing 3D obb metric\n",
      "2024-09-14 22:34:23,803-INFO:DONE Computing 3D obb metric in 1.2227246761322021 seconds\n",
      "2024-09-14 22:34:23,803-INFO:Object Detection Model Performance Summary\n",
      "=======Overall mAP Scores across all classes=======\n",
      "mAP (Average across IoU thresholds, defined by MeanAveragePrecision3D class, default is [0.05, 0.10, 0.15, ..., 0.5]): 0.4383\n",
      "Average precision (IoU=0.20): 0.5631\n",
      "Average recall (IoU=0.20): 0.5891\n",
      "===mAP across IoU thresholds [0.05, 0.10, 0.15, ..., 0.5]) per Class===\n",
      "Display: 0.9791\n",
      "Sofa: 0.9786\n",
      "Chair: 0.9493\n",
      "Table: 0.9208\n",
      "Bin: 0.7973\n",
      "Bookcase: 0.6633\n",
      "Door: 0.5590\n",
      "Shelves: 0.5004\n",
      "Bottle: 0.4413\n",
      "Cup: 0.3676\n",
      "Box: 0.3440\n",
      "Night Stand: 0.2667\n",
      "Lamp: 0.2576\n",
      "Clock: 0.2532\n",
      "Vase: 0.1382\n",
      "Books: 0.1299\n",
      "Tray: 0.1293\n",
      "Picture: 0.0695\n",
      "Candle: 0.0205\n",
      "Plant: 0.0000\n",
      "=======Timestamp Information=======\n",
      "Number of timestamps: 30\n",
      "Number of timestamps with missing ground truth: 0\n",
      "Number of timestamps with missing predictions: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmarking_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/benchmarking_static_object_detection.py\",\n",
    "    \"--pred-csv\", f\"{data_dir}/prediction_obbs.csv\",\n",
    "    \"--gt-csv\", f\"{data_dir}/gt_obbs.csv\",\n",
    "    \"--output-file\", f\"{data_dir}/atek_metrics.json\"\n",
    "]\n",
    "return_code = run_command_and_display_output(benchmarking_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4
}
