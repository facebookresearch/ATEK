{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb6e913",
   "metadata": {},
   "source": [
    "# ATEK Demo 2: ATEK Data Store\n",
    "In Demo 1 (TODO: add link here), we showed how to preprocess Aria data sequences into WebDataset (WDS) files, which can later be loaded directly into PyTorch DataLoaders. However, preprocessing large datasets are time- and resource-consuming. Hence ATEK provides users with a **ATEK Data Store**, where users can directly download preprocessed Aria datasets, completely skipping the preprocessing step. \n",
    "\n",
    "This demo walks through the steps for accessing datasets on ATEK Data Store. Here, we use preprocessed AriaDigitalTwin dataset as an example. See link for full list of datasets on ATEK Data Store. (TODO: add link to wiki page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83982be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.viz.atek_visualizer_base import NativeAtekSampleVisualizer\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.util.file_io_utils import load_yaml_and_extract_tar_list\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764dfc3",
   "metadata": {},
   "source": [
    "### Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data/\")\n",
    "data_dir = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun\"\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "viz_conf = OmegaConf.load(os.path.join(atek_src_path, \"atek\", \"configs\", \"obb_viz_new.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a361c81-6c71-4e0b-ac7e-2a4c109e8097",
   "metadata": {},
   "source": [
    "## Download and process ATEK data json file from ATEK Data Store\n",
    "First, user can download `AriaDigitalTwin_ATEK_download_urls.json` file from ATEK Data Store. This json file contains the ATEK WDS information for preprocessed ADT data. (TODO: add link to download guidance). \n",
    "\n",
    "Now, users have 2 options to access the data: \n",
    "1. They can download (a selection) of WDS files to local. This is recommended for training.\n",
    "2. They can also directly stream WDS files via their URLs. Because the URLs expire every 30 days, this is only recommended for small-scale local testing and exploration.\n",
    "\n",
    "Below we demonstrates both approaches.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7448d2-be9e-486a-b2a6-de6be1a06948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, download json file from ATEK Data Store \n",
    "atek_json_path = os.path.join(data_dir, \"AriaDigitalTwin_ATEK_download_urls.json\")\n",
    "if not os.path.exists(atek_json_path):\n",
    "    logger.error(\"Please download AriaDigitalTwin_ATEK_download_urls.json from ATEK Data Store\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8fc0f-a68c-4d96-bd2c-3234c22355ca",
   "metadata": {},
   "source": [
    "## [Option 1] Download from ATEK Data Store to local\n",
    "To download, user should use the `dataverse_url_parser.py` script in ATEK's lib, with `--download-wds-to-local` flag. User can select which preprocessing config to download, train/validation split, and number of sequences to download. The output folder will contain downloaded WDS data, along with 3 yaml files `local_all/train/validation_tars.yaml`, each containing the relative path of the downloaded files, and can be consumed by ATEK lib (usage shown later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f8b8e-bf5c-4c2e-9af4-b2a83526d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke ATEK's url parser tool to download files\n",
    "download_to_local_command = (\n",
    "    f\"python3 {atek_src_path}/tools/dataverse_url_parser.py\"\n",
    "    f\" --config-name cubercnn\" \n",
    "    f\" --input-json-path {atek_json_path}\" \n",
    "    f\" --output-folder-path {data_dir}/downloaded_local_wds_2/\" \n",
    "    f\" --max-num-sequences 2 \"\n",
    "    f\" --download-wds-to-local\"\n",
    ")\n",
    "\n",
    "# TODO: Try to run the command  here, and re-direct stdout to Notebook in real time. \n",
    "logger.info(f\"Please run the following command in a Terminal window to download WDS files to local: \")\n",
    "logger.info(f\"mamba activate atek; {download_to_local_command}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2ab37-00f7-4336-9c1e-c14c2b09f973",
   "metadata": {},
   "source": [
    "## [Option 2] Create Streamable yaml files\n",
    "User can also use `dataverse_url_parser.py` script **without** the `--download-wds_to-local` flag, which will just create 3 yaml files, `streamable_all/train/validation_tars.yaml`, each containing the urls of the WDS shard files. These yaml files can be consumed by ATEK lib (usage shown later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb745b3e-b7ef-49ff-860a-cc982c413a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke ATEK's url parser tool to download files\n",
    "create_streamable_yaml_command = (\n",
    "    f\"python3 {atek_src_path}/tools/dataverse_url_parser.py\"\n",
    "    f\" --config-name cubercnn\" \n",
    "    f\" --input-json-path {atek_json_path}\" \n",
    "    f\" --output-folder-path {data_dir}/streamable_yamls/\" \n",
    "    f\" --max-num-sequences 5 \"\n",
    ")\n",
    "\n",
    "# TODO: Try to run the command  here, and re-direct stdout to Notebook in real time. \n",
    "logger.info(f\"Please run the following command in a Terminal window to create streamable json files: \")\n",
    "logger.info(f\"mamba activate atek; {create_streamable_yaml_command}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b7c94",
   "metadata": {},
   "source": [
    "## Create PyTorch data loaders from the yaml files\n",
    "Now user can create a list of tar urls, from either the `local_*.yaml` or the `streamable_*.yaml`, and further create a Pytorch DataLoader to load the WDS content (See Demo 1 - Example 2). Here, we demonstrate how to visualize the WDS content, using the **streamable** yaml files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Native ATEK WDS data\n",
    "logger.info(\"-------------------- streaming ATEK data directly from DataStore --------------- \")\n",
    "\n",
    "# Loading local WDS files\n",
    "tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"streamable_yamls\", \"streamable_validation_tars.yaml\"))\n",
    "\n",
    "# Batch size is None so that no collation is invoked\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size=None, repeat_flag=False)\n",
    "\n",
    "# Loop over all samples in DataLoader and visualize\n",
    "atek_visualizer = NativeAtekSampleVisualizer(viz_prefix = \"dataloading_visualizer\", conf = viz_conf)\n",
    "for atek_sample_dict in atek_dataloader:\n",
    "    # First convert it back to ATEK data sample and visualize\n",
    "    atek_visualizer.plot_atek_sample_as_dict(atek_sample_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
