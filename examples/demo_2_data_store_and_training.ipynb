{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb6e913",
   "metadata": {},
   "source": [
    "# ATEK Demo 2: ATEK Data Store and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83982be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.util.file_io_utils import load_yaml_and_extract_tar_list\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    \n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764dfc3",
   "metadata": {},
   "source": [
    "### Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data/\")\n",
    "data_dir = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun\"\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "viz_conf = OmegaConf.load(os.path.join(atek_src_path, \"atek\", \"configs\", \"obb_viz.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a361c81-6c71-4e0b-ac7e-2a4c109e8097",
   "metadata": {},
   "source": [
    "## Part 1: ATEK Data Store\n",
    "**ATEK Data Store** is a place where users can directly download preprocessed Aria datasets in WebDataset (WDS) format, completely skipping the preprocessing step. This demo walks through the steps for accessing datasets on ATEK Data Store. \n",
    "\n",
    "1. Download `AriaDigitalTwin_ATEK_download_urls.json` from [Dataverse](https://www.internalfb.com/manifold/explorer/surreal_atek_public/flat/AriaSyntheticEnvironment_ATEK_download_urls.json).  \n",
    "2. Call `tools/dataverse_url_parser.py` to parse json file:\n",
    "    1. [Option 1] Create streamable-version yaml files.\n",
    "    2. [Option 2] Download the WDS files and create local-version yaml files. \n",
    "3. Load yaml files in ATEK lib.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7448d2-be9e-486a-b2a6-de6be1a06948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, download json file from ATEK Data Store \n",
    "atek_json_path = os.path.join(data_dir, \"AriaDigitalTwin_ATEK_download_urls.json\")\n",
    "if not os.path.exists(atek_json_path):\n",
    "    logger.error(\"Please download AriaDigitalTwin_ATEK_download_urls.json from ATEK Data Store\")\n",
    "    exit()\n",
    "\n",
    "# Second, parse into streamable yaml files\n",
    "create_streamable_yaml_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/dataverse_url_parser.py\",\n",
    "    \"--config-name\",\"cubercnn\", \n",
    "    \"--input-json-path\",f\"{atek_json_path}\",\n",
    "    \"--output-folder-path\",f\"{data_dir}/streamable_yamls/\",\n",
    "    \"--max-num-sequences\", \"5\",\n",
    "    \"--train-val-split-ratio\", \"0.8\"\n",
    "]\n",
    "return_code = run_command_and_display_output(create_streamable_yaml_command)\n",
    "\n",
    "# Create ATEK data loader from streamable yaml file\n",
    "tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"streamable_yamls\", \"streamable_validation_tars.yaml\"))\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size=None, repeat_flag=False)\n",
    "\n",
    "# Visualize ATEK WDS files in streaming mode\n",
    "atek_visualizer = NativeAtekSampleVisualizer(viz_prefix = \"dataloading_visualizer\", conf = viz_conf)\n",
    "for atek_sample_dict in atek_dataloader:\n",
    "    atek_visualizer.plot_atek_sample_as_dict(atek_sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42fccc-302b-4d5a-ae09-f51c1c44b8fa",
   "metadata": {},
   "source": [
    "## Part 2: ATEK Training example with CubeRCNN\n",
    "User can call our `tools/train_cubercnn.py` script to do a mini-scale training on downloaded data. We will run this on my local machine for a mini demonstration.  \n",
    "\n",
    "Core code snippets in the script (check out the script for full details): \n",
    "```\n",
    "model.train()\n",
    "tar_file_urls = load_yaml_and_extract_tar_list(train_list_yaml)\n",
    "data_loader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, ...)\\\n",
    "\n",
    "# Loop over cubercnn-format data samples\n",
    "for sample_data in data_loader:\n",
    "    # Training step\n",
    "    loss_dict = model(data)\n",
    "    losses = sum(loss_dict.values())\n",
    "    optimizer.zero_grad()\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c78f8-b66c-473b-a1e0-4f3ab4541b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training command\n",
    "mini_training_command = [\n",
    "  f\"python\",f\"{atek_src_path}/tools/train_cubercnn.py\",\n",
    "  \"--config-file\",f\"{data_dir}/cubercnn_train_config_mini_example.yaml\",\n",
    "  \"--num-gpus\", \"1\", \n",
    "  \"OUTPUT_DIR\", f\"{data_dir}/mini_test_1\",\n",
    "  \"TRAIN_LIST\",f\"{data_dir}/streamable_yamls/streamable_train_tars.yaml\",\n",
    "  \"TEST_LIST\", f\"{data_dir}/streamable_yamls/streamable_validation_tars.yaml\", \n",
    "  \"CATEGORY_JSON\", f\"{atek_src_path}/data/atek_id_to_name.json\",\n",
    "  \"ID_MAP_JSON\", f\"{atek_src_path}/data/atek_name_to_id.json\", \n",
    "  \"MODEL.WEIGHTS_PRETRAIN\", f\"/home/louy/Calibration_data_link/Atek/cubercnn_DLA34_FPN.pth\"\n",
    "]\n",
    "return_code = run_command_and_display_output(mini_training_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c43179-decf-41a4-911c-610424a4a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training progress using tensorboard\n",
    "tensorboard_command = [\"tensorboard\", f\"--logdir={workdir}/mini_test_1\", \"--port\", \"6007\", \"--samples_per_plugin=images=1000\"]\n",
    "return_code = run_command_and_display_output(tensorboard_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
