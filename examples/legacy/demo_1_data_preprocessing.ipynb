{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6157a668-b1e4-42d1-a785-cd72c78da045",
   "metadata": {},
   "source": [
    "# ATEK Demo 1: ATEK data preprocessing + model inference\n",
    "\n",
    "This demo will walk through the steps of preparing an Aria data sequence with annotations ([AriaDigitalTwin (ADT)](https://www.projectaria.com/datasets/adt/)), for use in a 3D object detection model CubeRCNN, run model inference on the preprocessed data, and evaluate the model performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d912d1-bfb6-48d1-98df-9577feab2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.data_preprocess.genera_atek_preprocessor_factory import (\n",
    "    create_general_atek_preprocessor_from_conf,\n",
    ")\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_preprocess.general_atek_preprocessor import GeneralAtekPreprocessor\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.data_preprocess.atek_data_sample import (\n",
    "    create_atek_data_sample_from_flatten_dict,\n",
    ")\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone  # noqa\n",
    "from cubercnn.modeling.meta_arch import build_model  # noqa\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Prettier colors\n",
    "COLOR_GREEN = [42,157,143]\n",
    "COLOR_RED = [231, 111, 81]\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def print_data_sample_dict_content(data_sample, if_pretty: bool = False):\n",
    "    \"\"\"\n",
    "    A helper function to print the content of data sample dict\n",
    "    \"\"\"\n",
    "    logger.info(\"Printing the content in a ATEK data sample dict: \")\n",
    "    for key, val in data_sample.items():\n",
    "        if if_pretty and \"#\" in key:\n",
    "            key = key.split(\"#\", 1)[1]\n",
    "\n",
    "        msg = f\"\\t {key}: is a {type(val)}, \"\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            msg += f\"with shape of : {val.shape}\"\n",
    "        elif isinstance(val, list):\n",
    "            msg += f\"with len of : {len(val)}\"\n",
    "        elif isinstance(val, str):\n",
    "            msg += f\"value is {val}\"\n",
    "        else:\n",
    "            pass\n",
    "        logger.info(msg)\n",
    "\n",
    "def create_inference_model(config_file, ckpt_dir, use_cpu_only=False):\n",
    "    \"\"\"\n",
    "    Create the model for inference pipeline, with the model config.\n",
    "    \"\"\"\n",
    "    # Create default model configuration\n",
    "    model_config = get_cfg()\n",
    "    get_cfg_defaults(model_config)\n",
    "\n",
    "    # add extra configs for data\n",
    "    model_config.MAX_TRAINING_ATTEMPTS = 3\n",
    "    model_config.TRAIN_LIST = \"\"\n",
    "    model_config.TEST_LIST = \"\"\n",
    "    model_config.TRAIN_WDS_DIR = \"\"\n",
    "    model_config.TEST_WDS_DIR = \"\"\n",
    "    model_config.ID_MAP_JSON = \"\"\n",
    "    model_config.OBJ_PROP_JSON = \"\"\n",
    "    model_config.CATEGORY_JSON = \"\"\n",
    "    model_config.DATASETS.OBJECT_DETECTION_MODE = \"\"\n",
    "    model_config.SOLVER.VAL_MAX_ITER = 0\n",
    "    model_config.SOLVER.MAX_EPOCH = 0\n",
    "\n",
    "    model_config.merge_from_file(config_file)\n",
    "    if use_cpu_only:\n",
    "        model_config.MODEL.DEVICE = \"cpu\"\n",
    "    model_config.freeze()\n",
    "\n",
    "    model = build_model(model_config, priors=None)\n",
    "\n",
    "    _ = DetectionCheckpointer(model, save_dir=ckpt_dir).resume_or_load(\n",
    "        model_config.MODEL.WEIGHTS, resume=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    return model_config, model\n",
    "\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae14104-0b7e-4518-9fc9-61d06e774fa8",
   "metadata": {},
   "source": [
    "## Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04466ffa-3e96-40d4-bb1c-0282c76bc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the following guide to download example ADT sequence to a local path `~/Documents/projectaria_tools_adt_data`\n",
    "# https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download.\n",
    "\n",
    "# Set up local data paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data\")\n",
    "sequence_name = \"Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "example_adt_data_dir = os.path.join(data_dir, sequence_name)\n",
    "output_wds_path = os.path.join(data_dir, \"wds_output\")\n",
    "\n",
    "# Set up ATEK paths\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "atek_preprocess_config_path = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/adt_cubercnn_preprocess_config.yaml\"\n",
    "category_mapping_file = os.path.join(atek_src_path, \"data\", \"adt_prototype_to_atek.csv\")\n",
    "preprocess_conf = OmegaConf.load(atek_preprocess_config_path)\n",
    "\n",
    "# Set up trained model weight path\n",
    "model_ckpt_path = \"/home/louy/Calibration_data_link/Atek/pre_trained_models/2024_08_28_AdtCubercnnWeights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c0f9f-e35b-46db-ad75-31c7d573f172",
   "metadata": {},
   "source": [
    "# Step 1: ATEK data preprocessing\n",
    "ADT sequence has: \n",
    "1. Aria recording (VRS).\n",
    "2. MPS trajectory file (CSV).\n",
    "3. Object detection annotation files (3 csv files + 1 json file).\n",
    "\n",
    "CubeRCNN model data samples (all in `torch.Tensor`): \n",
    "1. Upright RGB camera image.\n",
    "2. Linear camera calibration matrix.\n",
    "3. Object bounding box annotations in 2D + 3D.\n",
    "4. Camera-to-object poses.\n",
    "\n",
    "**Before ATEK**, users need to implement all the followings to prepare ADT sequence into CubeRCNN model: \n",
    "1. Parse in ADT sequence data using `projectaria_tools` lib.   \n",
    "2. Linearize image + camera calibration.\n",
    "3. Rescale camera resolution. \n",
    "4. Rotate image + camera calibration.\n",
    "5. Linearize + rescale + rotate object 2D bounding boxes accordingly.\n",
    "6. Synchronize sensor + annotation data into training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb1902-c22b-4e54-9cc2-802e5b57b445",
   "metadata": {},
   "source": [
    "### Set up and run ATEK data preprocessor\n",
    "**With ATEK**, all these above preprocessing can be handled by a simple  [configurable yaml file](https://www.internalfb.com/phabricator/paste/view/P1581100261). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0343b9-19e3-4cc9-be19-a4122a651fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ATEK preprocessor from conf. It will automatically choose which type of sample to build.\n",
    "atek_preprocessor = create_general_atek_preprocessor_from_conf(\n",
    "    # [required]\n",
    "    conf=preprocess_conf,\n",
    "    raw_data_folder = example_adt_data_dir,\n",
    "    sequence_name = sequence_name,\n",
    "    # [optional]\n",
    "    output_wds_folder=output_wds_path,\n",
    "    category_mapping_file=category_mapping_file,\n",
    ")\n",
    "\n",
    "# Loop over all samples, and write valid ones to local tar files.\n",
    "atek_preprocessor.process_all_samples(write_to_wds_flag=True, viz_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ae03a-6b21-4f8d-b6d5-1b905adc2cae",
   "metadata": {},
   "source": [
    "## Preprocessed ATEK data sample content\n",
    "Converted from VRS + csv + jsons -> `Dict[torch.Tensor, str, or Dict]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf10872-81f0-4585-98eb-58e9642427ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the content of a ATEK data sample (in memory)\n",
    "atek_data_sample = atek_preprocessor[0]\n",
    "print_data_sample_dict_content(atek_data_sample.to_flatten_dict())\n",
    "\n",
    "# print the preprocessed files that are saved to disk\n",
    "print(\"\\nPrinting the preprocessed results that are saved to disk\")\n",
    "listing_command = [\"ls\", f\"{output_wds_path}\"]\n",
    "return_code = run_command_and_display_output(listing_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270be43e-15e4-4aae-9791-4cb58a655a5c",
   "metadata": {},
   "source": [
    "# Step 2: Run Object detection inference using pre-trained CubeRCNN model\n",
    "In this example, we demonstrate how to run model inference with preprocessed ATEK data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ff6e1-a722-4883-8a53-1ec65f41ab06",
   "metadata": {},
   "source": [
    "### Create a PyTorch DataLoader from ATEK WDS files\n",
    "Load WDS files as ATEK format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e5e91-7ac3-45fa-9e42-f175c1c2e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ATEK dataloader with native ATEK format.\n",
    "tar_file_urls = [os.path.join(output_wds_path, f\"shards-000{i}.tar\") for i in range(2)]\n",
    "\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size = None, num_workers = 1)\n",
    "first_atek_sample = next(iter(atek_dataloader))\n",
    "logger.info(f\"Loading WDS into ATEK natvie format, each sample contains the following keys: {first_atek_sample.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d17b53-a27a-4d53-b697-41adcebd5fd5",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader, converted to CubeRCNN format\n",
    "Data converter from ATEK format -> CubeRCNN format: \n",
    "1. Dict key renaming.\n",
    "2. Tensor reshaping & reordering. \n",
    "3. Other data transformations.\n",
    "\n",
    "Example data converter impl for CubeRCNN model: [src code](https://www.internalfb.com/code/fbsource/[a5c3831c045bc718862d1c512e84d4ed6f79d722]/fbcode/surreal/data_services/atek/atek/data_loaders/cubercnn_model_adaptor.py?lines=44-74)\n",
    "\n",
    "The `create_atek_dataloader_as_cubercnn` API is a thin wrapper on top of a `CubeRCNN` data converter class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b459d-0efa-4924-951e-f28426d04c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 6, num_workers = 1)\n",
    "first_cubercnn_sample = next(iter(cubercnn_dataloader))\n",
    "logger.info(f\"Loading WDS into CubeRCNN format, each sample contains the following keys: {first_cubercnn_sample[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e76a1-c7be-4775-930d-1e70c24351a4",
   "metadata": {},
   "source": [
    "### Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbe6f7-6aaa-42d0-bfb7-0e3627a1035b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load pre-trained CubeRCNN model\n",
    "model_config_file = os.path.join(model_ckpt_path, \"config.yaml\")\n",
    "conf = OmegaConf.load(model_config_file)\n",
    "\n",
    "# setup config and model\n",
    "model_config, model = create_inference_model(\n",
    "    model_config_file, model_ckpt_path, False\n",
    ")\n",
    "\n",
    "\n",
    "# Cache inference results for visualization\n",
    "input_output_data_pairs = []\n",
    "\n",
    "# Loop over created Pytorch Dataloader\n",
    "with torch.no_grad():\n",
    "    for cubercnn_input_data in tqdm(\n",
    "       cubercnn_dataloader,\n",
    "        desc=\"Inference progress: \",\n",
    "    ):\n",
    "        cubercnn_model_output = model(cubercnn_input_data)\n",
    "\n",
    "        # cache inference results for visualization\n",
    "        input_output_data_pairs.append((cubercnn_input_data, cubercnn_model_output))\n",
    "\n",
    "logger.info(\"Inference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e116f-27d2-45f3-87eb-6f97e1df3dc0",
   "metadata": {},
   "source": [
    "### Visualize inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414faf58-78a6-446b-9972-3fea91d19b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.viz.cubercnn_visualizer import CubercnnVisualizer\n",
    "\n",
    "# Visualize cached inference results\n",
    "logger.info(\"Visualizing inference results.\")\n",
    "viz_conf = preprocess_conf.visualizer\n",
    "cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", conf = viz_conf)\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        # Plot RGB image\n",
    "        cubercnn_visualizer.plot_cubercnn_img(single_cubercnn_input[\"image\"], timestamp_ns = timestamp_ns)\n",
    "\n",
    "        # Plot GT and prediction in different colors\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"] # This patch is needed for visualization\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_GREEN, suffix = \"_model_input\")\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_RED, suffix = \"_model_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084f7d2-0a67-491e-9797-a4fc8378d4c5",
   "metadata": {},
   "source": [
    "# Step 3: Evaluate model performance\n",
    "Hard to compare model performances within Aria community: \n",
    "1. Different file formats. \n",
    "2. Different metrics impl.\n",
    "\n",
    "ATEK provides: \n",
    "1. Standardized prediction file format for each ML task.\n",
    "2. Standardized benchmarking scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ac31b-2308-4fbe-b361-a33b9c8906b3",
   "metadata": {},
   "source": [
    "### Write inference results into ATEK-format csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c34b1-f946-4a0a-8fbb-9b7902b61d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "\n",
    "gt_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"gt_obbs.csv\"))\n",
    "prediction_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"prediction_obbs.csv\"))\n",
    "\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"]\n",
    "\n",
    "        gt_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns)\n",
    "        prediction_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304c717-528e-4212-85cf-eb07d2c2ce4c",
   "metadata": {},
   "source": [
    "### Call ATEK's benchmarking script to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e263d7-88ba-43af-b0ac-58e32b9d075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/benchmarking_static_object_detection.py\",\n",
    "    \"--pred-csv\", f\"{data_dir}/prediction_obbs.csv\",\n",
    "    \"--gt-csv\", f\"{data_dir}/gt_obbs.csv\",\n",
    "    \"--output-file\", f\"{data_dir}/atek_metrics.json\"\n",
    "]\n",
    "return_code = run_command_and_display_output(benchmarking_command)"
   ]
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "8cca9f3e-a062-4627-9916-8f40d129e10f",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4
}
