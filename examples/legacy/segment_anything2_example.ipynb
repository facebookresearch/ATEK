{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe32552-1081-4746-b03a-7a150edbc17c",
   "metadata": {},
   "source": [
    "# Examaple: Segment Anything 2\n",
    "\n",
    "This notebook demonstrates how to create a model adapter for ATEK data samples. The adapter converts ATEK data into a format compatible with the SAM2 model using the ATEK library. We will walk you through three key steps: loading the dataset, adapting it for compatibility, and performing inference with the SAM2 model.\n",
    "\n",
    "Segment Anything 2: https://github.com/facebookresearch/segment-anything-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700b6d9-f6d2-49a0-889e-2988b051da0d",
   "metadata": {},
   "source": [
    "## Set up environment\n",
    "\n",
    "1. Follow the official guide on SAM2 github repo to install: https://github.com/facebookresearch/segment-anything-2\n",
    "SAM2 requires python>=3.10, as well as torch>=2.3.1 and torchvision>=0.18.1.\n",
    "2. Download checkpoints, we choose sam2_hiera_large: https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\n",
    "put checkpoint into a path you like. You will need to feed path in the code below.\n",
    "activate atek environment\n",
    "2. Assume you have installed ATEK environment, you can select atek as kernel for jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f025a0-0c9a-4218-8477-1d900d55178e",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "First, we import all necessary libraries that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab7ae92-226f-4b31-8e5a-bfe1d6c04f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import webdataset as wds\n",
    "from atek.data_loaders.atek_wds_dataloader import load_atek_wds_dataset\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from webdataset.filters import pipelinefilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2693d54-3990-4525-aaff-80070ef01132",
   "metadata": {},
   "source": [
    "## Configuration and Initialization\n",
    "Define the paths and configuration parameters that will be used to load the data and the model. You can also specify the MAX segmentation number by NUM_BOXES_TO_SEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c27e30-f34d-4e26-8947-f32522e7957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wds_dir = (\n",
    "    \"/Users/ariak/coding/dataset/atek_exp/inference/20240808_inference_test/wds_output\"\n",
    ")\n",
    "checkpoint = \"/Users/ariak/coding/segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "NUM_BOXES_TO_SEG = 10\n",
    "\n",
    "output_video_path = \"/Users/ariak/Downloads/SAM_20.mp4\"\n",
    "output_image_folder_path = \"/Users/ariak/Downloads/SAM_20_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755beec-8403-46d4-aa4e-9cb5a1962e19",
   "metadata": {},
   "source": [
    "## Model Adaptor from SAM2 to ATEK\n",
    "We need to adapt the ATEK data sample to be compatible with SAM2. This class handles the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e2b8e-e711-4a95-bc1b-47fb1fa0ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sam2Adaptor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_boxes: int = 5,\n",
    "    ):\n",
    "        self.num_boxes = num_boxes\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dict_key_mapping_all():\n",
    "        dict_key_mapping = {\"mfcd#camera-rgb+images\": \"image\", \"gt_data\": \"gt_data\"}\n",
    "        return dict_key_mapping\n",
    "\n",
    "    def atek_to_sam2(self, data):\n",
    "        for atek_wds_sample in data:\n",
    "            sample = {}\n",
    "\n",
    "            # Add images\n",
    "            # from [1, C, H, W] to [H, W, C]\n",
    "            image_torch = atek_wds_sample[\"image\"].clone().detach()\n",
    "            image_np = image_torch.squeeze(0).permute(1, 2, 0).numpy()\n",
    "            sample[\"image\"] = image_np\n",
    "\n",
    "            # Select\n",
    "            obb2_gt = atek_wds_sample[\"gt_data\"][\"obb2_gt\"][\"camera-rgb\"]\n",
    "            num_box = min(self.num_boxes, len(obb2_gt[\"category_names\"]))\n",
    "            bbox_ranges = obb2_gt[\"box_ranges\"][\n",
    "                0:num_box, [0, 2, 1, 3]\n",
    "            ]  # First K bboxes, [K, 4], xxyy -> xyxy\n",
    "            sample[\"boxes\"] = bbox_ranges.numpy()  # xxyy -> xyxy\n",
    "\n",
    "            yield sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843510b-a0e5-448a-9494-88c178b6f4be",
   "metadata": {},
   "source": [
    "## Data Loading Function\n",
    "load_atek_wds_dataset_as_sam2 loads the ATEK dataset and applies the adaptor to make it compatible with SAM2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc6095-6bab-4946-bcc5-5d6d7c88c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_collation_fn(batch):\n",
    "    # Simply collate as a list\n",
    "    return list(batch)\n",
    "\n",
    "\n",
    "def load_atek_wds_dataset_as_sam2(\n",
    "    urls: List,\n",
    "    batch_size: int,\n",
    "    repeat_flag: bool,\n",
    "    shuffle_flag: bool = False,\n",
    "    num_boxes: int = 5,\n",
    "):\n",
    "    adaptor = Sam2Adaptor(num_boxes=num_boxes)\n",
    "\n",
    "    return load_atek_wds_dataset(\n",
    "        urls,\n",
    "        batch_size=batch_size,\n",
    "        dict_key_mapping=Sam2Adaptor.get_dict_key_mapping_all(),\n",
    "        data_transform_fn=pipelinefilter(adaptor.atek_to_sam2)(),\n",
    "        collation_fn=simple_collation_fn,\n",
    "        repeat_flag=repeat_flag,\n",
    "        shuffle_flag=shuffle_flag,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ed5fc-4335-4c53-b68b-f1e79255a425",
   "metadata": {},
   "source": [
    "## Visualization from SAM2\n",
    "These functions are used to visualize the results of the SAM2 model predictions. These functions are copied from a SAM2 example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70a0ee-889d-442e-aad5-770a8a2d0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False, borders=True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # Try to smooth contours\n",
    "        contours = [\n",
    "            cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours\n",
    "        ]\n",
    "        mask_image = cv2.drawContours(\n",
    "            mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2\n",
    "        )\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "    )\n",
    "\n",
    "\n",
    "def show_masks(\n",
    "    image,\n",
    "    masks,\n",
    "    scores,\n",
    "    point_coords=None,\n",
    "    box_coords=None,\n",
    "    input_labels=None,\n",
    "    borders=True,\n",
    "):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068b92e-2a13-4929-8a76-f739e6104257",
   "metadata": {},
   "source": [
    "## Main Inference Function\n",
    "This function sets up the model, loads the data, performs inference, and visualizes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878e490-d692-4c4b-99e2-1df5dc4440dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    # create SAM2 predictor\n",
    "    predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "\n",
    "    # load ATEK dataset\n",
    "    tar_list = [os.path.join(wds_dir, f\"shards-000{i}.tar\") for i in range(5)]\n",
    "    sam2_dataset = load_atek_wds_dataset_as_sam2(\n",
    "        tar_list,\n",
    "        batch_size=1,\n",
    "        repeat_flag=False,\n",
    "        shuffle_flag=False,\n",
    "        num_boxes=NUM_BOXES_TO_SEG,\n",
    "    )\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "\n",
    "        for sam_dict_list in sam2_dataset:\n",
    "            for sam_dict in sam_dict_list:\n",
    "                # perform inference\n",
    "                image = sam_dict[\"image\"]  # [1, 3, H, W]\n",
    "                predictor.set_image(image)\n",
    "\n",
    "                masks, scores, _ = predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=sam_dict[\"boxes\"],\n",
    "                    multimask_output=False,\n",
    "                )\n",
    "\n",
    "                # Visualize results (taken from SAM2's own visualization code)\n",
    "                print(f\" SAM2 resulting mask shapes are {masks.shape}\")\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                plt.imshow(image)\n",
    "                for mask in masks:\n",
    "                    show_mask(\n",
    "                        mask.squeeze(0), plt.gca(), random_color=True, borders=False\n",
    "                    )\n",
    "                for box in sam_dict[\"boxes\"]:\n",
    "                    show_box(box, plt.gca())\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                input(\"Press Enter to continue...\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
