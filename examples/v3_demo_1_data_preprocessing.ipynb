{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1877ecf-8c93-4842-a6b9-a8597c373e81",
   "metadata": {},
   "source": [
    "# ATEK Demo 1: ATEK data preprocessing\n",
    "\n",
    "* 3D object detection ML task.\n",
    "* An example model: CubeRCNN. \n",
    "* An example data sequence with Aria VRS recording: [Aria Digtial Twin (ADT)](https://www.projectaria.com/datasets/adt/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30426e9-9b9a-4a9c-9d89-e38f4688c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.data_preprocess.genera_atek_preprocessor_factory import (\n",
    "    create_general_atek_preprocessor_from_conf,\n",
    ")\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_preprocess.general_atek_preprocessor import GeneralAtekPreprocessor\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.data_preprocess.atek_data_sample import (\n",
    "    create_atek_data_sample_from_flatten_dict,\n",
    ")\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone  # noqa\n",
    "from cubercnn.modeling.meta_arch import build_model  # noqa\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Prettier colors\n",
    "COLOR_GREEN = [42,157,143]\n",
    "COLOR_RED = [231, 111, 81]\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def print_data_sample_dict_content(data_sample, if_pretty: bool = False):\n",
    "    \"\"\"\n",
    "    A helper function to print the content of data sample dict\n",
    "    \"\"\"\n",
    "    logger.info(\"Printing the content in a ATEK data sample dict: \")\n",
    "    for key, val in data_sample.items():\n",
    "        if if_pretty and \"#\" in key:\n",
    "            key = key.split(\"#\", 1)[1]\n",
    "\n",
    "        msg = f\"\\t {key}: is a {type(val)}, \"\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            msg += f\"\\n \\t\\t\\t\\t with tensor dtype of {val.dtype}, and shape of : {val.shape}\"\n",
    "        elif isinstance(val, list):\n",
    "            msg += f\"with len of : {len(val)}\"\n",
    "        elif isinstance(val, str):\n",
    "            msg += f\"value is {val}\"\n",
    "        else:\n",
    "            pass\n",
    "        logger.info(msg)\n",
    "\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f831e-ec3c-4e91-afed-3067fdc3a69d",
   "metadata": {},
   "source": [
    "###  Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3837d79d-b7e8-4a2a-b264-bb104e4b475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the following guide to download example ADT sequence to a local path `~/Documents/projectaria_tools_adt_data`\n",
    "# https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download.\n",
    "\n",
    "# Set up local data paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data\")\n",
    "sequence_name = \"Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "example_adt_data_dir = os.path.join(data_dir, sequence_name)\n",
    "output_wds_path = os.path.join(data_dir, \"wds_output\")\n",
    "\n",
    "# Set up ATEK paths\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "atek_preprocess_config_path = \"/home/louy/Calibration_data_link/Atek/2024_08_05_DryRun/adt_cubercnn_preprocess_config.yaml\"\n",
    "category_mapping_file = os.path.join(atek_src_path, \"data\", \"adt_prototype_to_atek.csv\")\n",
    "preprocess_conf = OmegaConf.load(atek_preprocess_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b73ba-cd9b-415c-abbc-a47f6e66ab62",
   "metadata": {},
   "source": [
    "###  Data preprocessing requirements\n",
    "ADT sequence has: \n",
    "1. Aria recording (VRS).\n",
    "2. MPS trajectory file (CSV).\n",
    "3. Object detection annotation files (3 csv files + 1 json file).\n",
    "\n",
    "CubeRCNN model needs synchronized data frame containing: \n",
    "1. Upright RGB camera image.\n",
    "2. Linear camera calibration matrix.\n",
    "3. Object bounding box annotations in 2D + 3D.\n",
    "4. Camera-to-object poses.\n",
    "\n",
    "**Before ATEK**, users need to implement all the followings to prepare ADT sequence into CubeRCNN model: \n",
    "1. Parse in ADT sequence data using `projectaria_tools` lib.   \n",
    "2. Properly synchronize sensor + annotation data into training samples.\n",
    "3. Perform additional image & data processing:\n",
    "    1. Undistort image + camera calibration.\n",
    "    2. Rescale camera resolution. \n",
    "    3. Rotate image + camera calibration.\n",
    "    4. Undistort + rescale + rotate object 2D bounding boxes accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f03e87-4375-4d3a-9124-73f72c663158",
   "metadata": {},
   "source": [
    "## Step 1: Set up and run ATEK data preprocessor\n",
    "**With ATEK**, all these above preprocessing can be handled by a simple  [configurable yaml file](https://www.internalfb.com/phabricator/paste/view/P1581100261). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3dbe5a-f243-49c8-bc50-cf11bd08002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 21:50:36,284 - INFO - Located ATEK data paths: {'video_vrs_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs', 'mps_closedloop_traj_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/aria_trajectory.csv', 'mps_semidense_points_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/mps/slam/semidense_points.csv.gz', 'mps_semidense_observations_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/mps/slam/semidense_observations.csv.gz', 'mps_online_calib_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/mps/slam/online_calibration.jsonl', 'depth_vrs_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/depth_images.vrs', 'gt_obb3_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/3d_bounding_box.csv', 'gt_obb3_traj_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/scene_objects.csv', 'gt_obb2_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/2d_bounding_box.csv', 'gt_instance_json_file': '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/instances.json'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-09-11 21:50:36: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading VRS data because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: No metadata file provided to data provider, setting the dataset version to Unknown.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: Unknown dataset version, we recommend loading with the metadata file to validate the dataset version is compatible with this version of the data provider.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: loading instance info from json file /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/instances.json\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileAriaTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSegmentation because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileDepth because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSynthetic because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonMetaDataFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonsFilePaths because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading eyeGazesFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading VRS data because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: No metadata file provided to data provider, setting the dataset version to Unknown.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: Unknown dataset version, we recommend loading with the metadata file to validate the dataset version is compatible with this version of the data provider.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: loading instance info from json file /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/instances.json\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading file3dBox because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileAriaTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileObjectTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSegmentation because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileDepth because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSynthetic because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonMetaDataFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonsFilePaths because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading eyeGazesFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-09-11 21:50:36: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m[2024-09-12T04:50:36Z INFO  re_sdk_comms::server] Hosting a SDK server over TCP at 0.0.0.0:9876. Connect with the Rerun logging SDK.\n",
      "[2024-09-12T04:50:36Z INFO  winit::platform_impl::platform::x11::window] Guessed window scale factor: 1\n",
      "[2024-09-12T04:50:36Z INFO  re_sdk_comms::server] New SDK client connected from: 127.0.0.1:46884\n",
      "[2024-09-12T04:50:36Z WARN  wgpu_hal::gles::adapter] Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "[2024-09-12T04:50:36Z WARN  wgpu_hal::gles::adapter] Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "[2024-09-12T04:50:36Z INFO  egui_wgpu] There were 4 available wgpu adapters: {backend: Vulkan, device_type: IntegratedGpu, name: \"Intel(R) UHD Graphics (TGL GT1)\", driver: \"Intel open-source Mesa driver\", driver_info: \"Mesa 24.1.6\", vendor: 0x8086, device: 0x9A60}, {backend: Vulkan, device_type: DiscreteGpu, name: \"NVIDIA GeForce RTX 3070 Laptop GPU\", driver: \"NVIDIA\", driver_info: \"555.58.02\", vendor: 0x10DE, device: 0x249D}, {backend: Vulkan, device_type: Cpu, name: \"llvmpipe (LLVM 18.1.6, 256 bits)\", driver: \"llvmpipe\", driver_info: \"Mesa 24.1.6 (LLVM 18.1.6)\", vendor: 0x10005}, {backend: Gl, device_type: IntegratedGpu, name: \"Mesa Intel(R) UHD Graphics (TGL GT1)\", driver: \"OpenGL\", driver_info: \"4.6 (Compatibility Profile) Mesa 24.1.7\", vendor: 0x8086}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded #closed loop trajectory poses records: 300\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0000.tar 0 0.0 GB 0\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0001.tar 32 0.0 GB 32\n",
      "2024-09-11 21:51:06,373 - INFO - Saving visualization to typing.Optional[str]\n",
      "2024-09-11 21:51:06,375 - INFO - ATEK has processed 50 valid samples in total.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ATEK preprocessor from conf. It will automatically choose which type of sample to build.\n",
    "atek_preprocessor = create_general_atek_preprocessor_from_conf(\n",
    "    # [required]\n",
    "    conf=preprocess_conf,\n",
    "    raw_data_folder = example_adt_data_dir,\n",
    "    sequence_name = sequence_name,\n",
    "    # [optional]\n",
    "    output_wds_folder=output_wds_path,\n",
    "    category_mapping_file=category_mapping_file,\n",
    ")\n",
    "\n",
    "# Loop over all samples, and write valid ones to local tar files.\n",
    "atek_preprocessor.process_all_samples(write_to_wds_flag=True, viz_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58562e8c-b1f2-4c45-9e29-34a2802561f9",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessed ATEK data sample content\n",
    "* Preprocessing input: VRS + csv + jsons\n",
    "* Preprocessing output (in memory): ATEK data samples: `Dict[torch.Tensor, str, or Dict]`\n",
    "* Preprocessing output (on local disk): WebDataset (WDS) tar files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74eb1245-7179-41b8-a070-95dbdd81eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 21:51:16,711 - INFO - Printing the content in a ATEK data sample dict: \n",
      "2024-09-11 21:51:16,711 - INFO - \t sequence_name: is a <class 'str'>, value is Apartment_release_golden_skeleton_seq100_10s_sample_M1292\n",
      "2024-09-11 21:51:16,711 - INFO - \t mfcd#camera-rgb+images: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.uint8, and shape of : torch.Size([1, 3, 1024, 1024])\n",
      "2024-09-11 21:51:16,712 - INFO - \t mfcd#camera-rgb+capture_timestamps_ns: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.int64, and shape of : torch.Size([1])\n",
      "2024-09-11 21:51:16,712 - INFO - \t mfcd#camera-rgb+frame_ids: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.int64, and shape of : torch.Size([1])\n",
      "2024-09-11 21:51:16,712 - INFO - \t mfcd#camera-rgb+exposure_durations_s: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float32, and shape of : torch.Size([1])\n",
      "2024-09-11 21:51:16,712 - INFO - \t mfcd#camera-rgb+gains: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float32, and shape of : torch.Size([1])\n",
      "2024-09-11 21:51:16,713 - INFO - \t mfcd#camera-rgb+camera_label: is a <class 'str'>, value is camera-rgb\n",
      "2024-09-11 21:51:16,713 - INFO - \t mfcd#camera-rgb+t_device_camera: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float64, and shape of : torch.Size([3, 4])\n",
      "2024-09-11 21:51:16,713 - INFO - \t mfcd#camera-rgb+camera_model_name: is a <class 'str'>, value is CameraModelType.LINEAR\n",
      "2024-09-11 21:51:16,713 - INFO - \t mfcd#camera-rgb+projection_params: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float64, and shape of : torch.Size([4])\n",
      "2024-09-11 21:51:16,714 - INFO - \t mfcd#camera-rgb+origin_camera_label: is a <class 'str'>, value is camera-slam-left\n",
      "2024-09-11 21:51:16,714 - INFO - \t mtd#ts_world_device: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float32, and shape of : torch.Size([1, 3, 4])\n",
      "2024-09-11 21:51:16,714 - INFO - \t mtd#capture_timestamps_ns: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.int64, and shape of : torch.Size([1])\n",
      "2024-09-11 21:51:16,714 - INFO - \t mtd#gravity_in_world: is a <class 'torch.Tensor'>, \n",
      " \t\t\t\t with tensor dtype of torch.float32, and shape of : torch.Size([3])\n",
      "2024-09-11 21:51:16,715 - INFO - \t gt_data: is a <class 'dict'>, \n",
      "\n",
      "Printing the preprocessed results that are saved to disk as WebDataset files (.tar)\n",
      "shards-0000.tar\n",
      "shards-0001.tar\n"
     ]
    }
   ],
   "source": [
    "# print the content of a ATEK data sample (in memory)\n",
    "atek_data_sample = atek_preprocessor[0]\n",
    "print_data_sample_dict_content(atek_data_sample.to_flatten_dict())\n",
    "\n",
    "# print the preprocessed files that are saved to disk\n",
    "print(\"\\nPrinting the preprocessed results that are saved to disk as WebDataset files (.tar)\")\n",
    "listing_command = [\"ls\", f\"{output_wds_path}\"]\n",
    "return_code = run_command_and_display_output(listing_command)"
   ]
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "8cca9f3e-a062-4627-9916-8f40d129e10f",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4
}
