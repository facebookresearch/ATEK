{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c39686b-870f-4f60-9725-380f911258d4",
   "metadata": {},
   "source": [
    "# ATEK Demo 1: ATEK data preprocessing -> visualization -> loading -> inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da77f10-7fba-4209-80ac-3c6348b35cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.data_preprocess.atek_wds_writer import AtekWdsWriter\n",
    "\n",
    "from atek.data_preprocess.sample_builders.obb_sample_builder import ObbSampleBuilder\n",
    "from atek.data_preprocess.subsampling_lib.temporal_subsampler import (\n",
    "    CameraTemporalSubsampler,\n",
    ")\n",
    "\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.data_preprocess.atek_data_sample import (\n",
    "    create_atek_data_sample_from_flatten_dict,\n",
    ")\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb9221-b967-4834-baeb-468b4d7a7b7d",
   "metadata": {},
   "source": [
    "### Helper functions used in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197ae094-a801-4b24-b414-0f242c5368ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_sample_dict_content(data_sample):\n",
    "    \"\"\"\n",
    "    A helper function to print the content of data sample dict\n",
    "    \"\"\"\n",
    "    for key, val in data_sample.items():\n",
    "        msg = f\"{key}: is a {type(val)}, \"\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            msg += f\"with shape of : {val.shape}\"\n",
    "        elif isinstance(val, list):\n",
    "            msg += f\"with len of : {len(val)}\"\n",
    "        elif isinstance(val, str):\n",
    "            msg += f\"value is {val}\"\n",
    "        else:\n",
    "            pass\n",
    "        logger.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34d5a7-b218-4728-aba1-b82735279e1c",
   "metadata": {},
   "source": [
    "## Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f3b758-7e8b-4d8f-b67a-71f8a43b1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the following guide to download example ADT sequence to a local path `~/Documents/projectaria_tools_adt_data`\n",
    "# https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download. \n",
    "\n",
    "# Set up local data paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"projectaria_tools_adt_data\")\n",
    "sequence_name = \"Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "example_adt_data_dir = os.path.join(data_dir, sequence_name)\n",
    "output_wds_path = os.path.join(data_dir, \"wds_output\")\n",
    "\n",
    "# Set up ATEK paths\n",
    "atek_src_path = os.path.join(os.path.expanduser(\"~\"), \"atek_on_fbsource\")\n",
    "atek_preprocess_config_path = os.path.join(atek_src_path, \"atek\", \"configs\", \"obb_preprocess_base.yaml\")\n",
    "atek_viz_config_path = os.path.join(atek_src_path, \"atek\", \"configs\", \"obb_viz.yaml\")\n",
    "category_mapping_file = os.path.join(atek_src_path, \"data\", \"adt_prototype_to_atek.csv\")\n",
    "\n",
    "# Set up trained model weight path\n",
    "# model_ckpt_path = os.path.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71518ea",
   "metadata": {},
   "source": [
    "# Example 1: ATEK data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbe062",
   "metadata": {},
   "source": [
    "### Step 2: Set up ATEK data preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ee123a-a424-454c-a1b1-997d03f36c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-28T21:50:46Z INFO  re_sdk_comms::server] Hosting a SDK server over TCP at 0.0.0.0:9876. Connect with the Rerun logging SDK.\n",
      "[2024-08-28T21:50:47Z INFO  winit::platform_impl::platform::x11::window] Guessed window scale factor: 1.0999959309895833\n",
      "[2024-08-28T21:50:47Z INFO  re_sdk_comms::server] New SDK client connected from: 127.0.0.1:42902\n",
      "[2024-08-28T21:50:47Z WARN  wgpu_hal::gles::egl] No config found!\n",
      "[2024-08-28T21:50:47Z WARN  wgpu_hal::gles::egl] EGL says it can present to the window but not natively\n",
      "[2024-08-28T21:50:47Z INFO  egui_wgpu] There were 3 available wgpu adapters: {backend: Vulkan, device_type: DiscreteGpu, name: \"NVIDIA GeForce RTX 3080\", driver: \"NVIDIA\", driver_info: \"550.76\", vendor: 0x10DE, device: 0x2216}, {backend: Vulkan, device_type: Cpu, name: \"llvmpipe (LLVM 16.0.6, 256 bits)\", driver: \"llvmpipe\", driver_info: \"Mesa 23.1.9 (LLVM 16.0.6)\", vendor: 0x10005}, {backend: Gl, device_type: Other, name: \"NVIDIA GeForce RTX 3080/PCIe/SSE2\", driver: \"OpenGL\", driver_info: \"4.6.0 NVIDIA 550.76\", vendor: 0x10DE}\n"
     ]
    }
   ],
   "source": [
    "# Set up a visualizer to visualize the preprocessed samples, on the fly\n",
    "viz_conf = OmegaConf.load(atek_viz_config_path)\n",
    "atek_visualizer = NativeAtekSampleVisualizer(viz_prefix = \"preprocess_visualizer\", conf = viz_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67352444-f834-4309-8bdc-f9c1fdcece6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-08-28 14:50:48: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-08-28 14:50:48: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-08-28 14:50:48: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading VRS data because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: No metadata file provided to data provider, setting the dataset version to Unknown.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: Unknown dataset version, we recommend loading with the metadata file to validate the dataset version is compatible with this version of the data provider.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: loading instance info from json file /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/instances.json\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileAriaTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSegmentation because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileDepth because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSynthetic because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonMetaDataFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonsFilePaths because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading eyeGazesFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading VRS data because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: No metadata file provided to data provider, setting the dataset version to Unknown.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[AriaDigitalTwinDataProvider][WARNING]: Unknown dataset version, we recommend loading with the metadata file to validate the dataset version is compatible with this version of the data provider.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: loading instance info from json file /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/instances.json\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading file3dBox because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileAriaTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileObjectTraj because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSegmentation because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileDepth because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading fileSynthetic because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonMetaDataFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading skeletonsFilePaths because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[AriaDigitalTwinDataProvider][INFO]: skip loading eyeGazesFilePath because the data path is empty\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2024-08-28 14:50:49: Opening /home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/home/louy/Documents/projectaria_tools_adt_data/Apartment_release_golden_skeleton_seq100_10s_sample_M1292/video.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Timecode stream found: 285-2\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Create object detection sample builder\n",
    "preprocess_conf = OmegaConf.load(atek_preprocess_config_path)\n",
    "atek_preprocessor = create_atek_preprocessor_from_conf(conf = preprocess_conf, raw_data_folder, output_wds_path, viz_conf = viz_conf)\n",
    "atek_preprocessor.process_all_data()\n",
    "    \n",
    "\n",
    "\n",
    "sample_builder = ObbSampleBuilder(\n",
    "    conf=conf.processors,\n",
    "    vrs_file=os.path.join(example_adt_data_dir, \"video.vrs\"),\n",
    "    sequence_name=sequence_name,\n",
    "    mps_files={\n",
    "        \"mps_closedloop_traj_file\": os.path.join(\n",
    "            example_adt_data_dir, \"aria_trajectory.csv\"\n",
    "        ),\n",
    "    },\n",
    "    gt_files={\n",
    "        \"obb3_file\": os.path.join(example_adt_data_dir, \"3d_bounding_box.csv\"),\n",
    "        \"obb3_traj_file\": os.path.join(example_adt_data_dir, \"scene_objects.csv\"),\n",
    "        \"obb2_file\": os.path.join(example_adt_data_dir, \"2d_bounding_box.csv\"),\n",
    "        \"instance_json_file\": os.path.join(example_adt_data_dir, \"instances.json\"),\n",
    "        \"category_mapping_file\": category_mapping_file,\n",
    "    },\n",
    ")\n",
    "\n",
    "# From config, create a class to subsample data\n",
    "subsampler = CameraTemporalSubsampler(\n",
    "    vrs_file=os.path.join(example_adt_data_dir, \"video.vrs\"),\n",
    "    conf=conf.camera_temporal_subsampler,\n",
    ")\n",
    "\n",
    "# Create WebDataset (WDS) writer to write preprocessed data to local\n",
    "atek_wds_writer = AtekWdsWriter(\n",
    "    output_path=output_wds_path,\n",
    "    conf=conf.wds_writer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc4b04-6122-4d25-8eb5-f1f42256c8c4",
   "metadata": {},
   "source": [
    "## Step 3: preprocess data samples, visualize them, and write to WDS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb3bf75-cbff-476f-a77f-8b1395ce9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded #closed loop trajectory poses records: 300\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0000.tar 0 0.0 GB 0\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0001.tar 32 0.0 GB 32\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0002.tar 32 0.0 GB 64\n",
      "# writing /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0003.tar 32 0.0 GB 96\n",
      "2024-08-28 14:51:23,524 - INFO - finish writing WDS in /home/louy/Documents/projectaria_tools_adt_data/wds_output\n",
      "2024-08-28 14:51:23,525 - INFO - Saving visualization to /home/louy/Documents/projectaria_tools_adt_data/example_atek_preprocess_viz_2.rrd\n"
     ]
    }
   ],
   "source": [
    "# Loop over all samples, and write valid ones to local tar files.\n",
    "for i in range(subsampler.get_total_num_samples()):\n",
    "    timestamps_ns = subsampler.get_timestamps_by_sample_index(i)\n",
    "\n",
    "    for t in timestamps_ns:\n",
    "        sample = sample_builder.get_sample_by_timestamp_ns(t)\n",
    "        if sample is not None:\n",
    "            atek_visualizer.plot_atek_sample(sample)\n",
    "            atek_wds_writer.add_sample(data_sample=sample)\n",
    "\n",
    "atek_wds_writer.close()\n",
    "logger.info(f\"finish writing WDS in {output_wds_path}\")\n",
    "\n",
    "# also save visualization file locally\n",
    "atek_visualizer.save_viz(rrd_output_path = os.path.join(data_dir, \"example_atek_preprocess_viz_2.rrd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e942f15-e6ac-4541-a115-f83a065c658e",
   "metadata": {},
   "source": [
    "# Example 2: load ATEK WDS files back as Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339a764-fe40-4d03-a680-d27732cb7d1d",
   "metadata": {},
   "source": [
    "## Step 1: Load ATEK WDS files natively, and visualize (as ATEK data sample dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92878e68-94ab-4f67-86d3-4bb851a26009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28 18:10:27,597 - INFO - -------------------- loading ATEK data natively --------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-29T01:10:27Z INFO  re_sdk_comms::server] Hosting a SDK server over TCP at 0.0.0.0:9876. Connect with the Rerun logging SDK.\n",
      "[2024-08-29T01:10:27Z INFO  winit::platform_impl::platform::x11::window] Guessed window scale factor: 1.0999959309895833\n",
      "[2024-08-29T01:10:27Z INFO  re_sdk_comms::server] New SDK client connected from: 127.0.0.1:59324\n",
      "[2024-08-29T01:10:27Z WARN  wgpu_hal::gles::egl] No config found!\n",
      "[2024-08-29T01:10:27Z WARN  wgpu_hal::gles::egl] EGL says it can present to the window but not natively\n",
      "[2024-08-29T01:10:27Z INFO  egui_wgpu] There were 3 available wgpu adapters: {backend: Vulkan, device_type: DiscreteGpu, name: \"NVIDIA GeForce RTX 3080\", driver: \"NVIDIA\", driver_info: \"550.76\", vendor: 0x10DE, device: 0x2216}, {backend: Vulkan, device_type: Cpu, name: \"llvmpipe (LLVM 16.0.6, 256 bits)\", driver: \"llvmpipe\", driver_info: \"Mesa 23.1.9 (LLVM 16.0.6)\", vendor: 0x10005}, {backend: Gl, device_type: Other, name: \"NVIDIA GeForce RTX 3080/PCIe/SSE2\", driver: \"OpenGL\", driver_info: \"4.6.0 NVIDIA 550.76\", vendor: 0x10DE}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28 18:10:44,195 - INFO - Loading native atek data sample as a Dict, containing the following: \n",
      "2024-08-28 18:10:44,251 - INFO - __key__: is a <class 'str'>, value is _AtekDataSample_000000\n",
      "2024-08-28 18:10:44,252 - INFO - __url__: is a <class 'str'>, value is /home/louy/Documents/projectaria_tools_adt_data/wds_output/shards-0000.tar\n",
      "2024-08-28 18:10:44,252 - INFO - gt_data: is a <class 'dict'>, \n",
      "2024-08-28 18:10:44,253 - INFO - mfcd#camera-rgb+camera_label: is a <class 'str'>, value is camera-rgb\n",
      "2024-08-28 18:10:44,253 - INFO - mfcd#camera-rgb+camera_model_name: is a <class 'str'>, value is CameraModelType.FISHEYE624\n",
      "2024-08-28 18:10:44,254 - INFO - mfcd#camera-rgb+capture_timestamps_ns: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,254 - INFO - mfcd#camera-rgb+exposure_durations_s: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,255 - INFO - mfcd#camera-rgb+frame_ids: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,256 - INFO - mfcd#camera-rgb+gains: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,256 - INFO - mfcd#camera-rgb+origin_camera_label: is a <class 'str'>, value is camera-slam-left\n",
      "2024-08-28 18:10:44,257 - INFO - mfcd#camera-rgb+projection_params: is a <class 'torch.Tensor'>, with shape of : torch.Size([15])\n",
      "2024-08-28 18:10:44,257 - INFO - mfcd#camera-rgb+t_device_camera: is a <class 'torch.Tensor'>, with shape of : torch.Size([3, 4])\n",
      "2024-08-28 18:10:44,258 - INFO - mfcd#camera-slam-left+camera_label: is a <class 'str'>, value is camera-slam-left\n",
      "2024-08-28 18:10:44,258 - INFO - mfcd#camera-slam-left+camera_model_name: is a <class 'str'>, value is CameraModelType.FISHEYE624\n",
      "2024-08-28 18:10:44,259 - INFO - mfcd#camera-slam-left+capture_timestamps_ns: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,259 - INFO - mfcd#camera-slam-left+exposure_durations_s: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,260 - INFO - mfcd#camera-slam-left+frame_ids: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,260 - INFO - mfcd#camera-slam-left+gains: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,260 - INFO - mfcd#camera-slam-left+origin_camera_label: is a <class 'str'>, value is camera-slam-left\n",
      "2024-08-28 18:10:44,261 - INFO - mfcd#camera-slam-left+projection_params: is a <class 'torch.Tensor'>, with shape of : torch.Size([15])\n",
      "2024-08-28 18:10:44,261 - INFO - mfcd#camera-slam-left+t_device_camera: is a <class 'torch.Tensor'>, with shape of : torch.Size([3, 4])\n",
      "2024-08-28 18:10:44,262 - INFO - mfcd#camera-slam-right+camera_label: is a <class 'str'>, value is camera-slam-right\n",
      "2024-08-28 18:10:44,262 - INFO - mfcd#camera-slam-right+camera_model_name: is a <class 'str'>, value is CameraModelType.FISHEYE624\n",
      "2024-08-28 18:10:44,263 - INFO - mfcd#camera-slam-right+capture_timestamps_ns: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,263 - INFO - mfcd#camera-slam-right+exposure_durations_s: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,265 - INFO - mfcd#camera-slam-right+frame_ids: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,266 - INFO - mfcd#camera-slam-right+gains: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,266 - INFO - mfcd#camera-slam-right+origin_camera_label: is a <class 'str'>, value is camera-slam-left\n",
      "2024-08-28 18:10:44,267 - INFO - mfcd#camera-slam-right+projection_params: is a <class 'torch.Tensor'>, with shape of : torch.Size([15])\n",
      "2024-08-28 18:10:44,267 - INFO - mfcd#camera-slam-right+t_device_camera: is a <class 'torch.Tensor'>, with shape of : torch.Size([3, 4])\n",
      "2024-08-28 18:10:44,267 - INFO - mtd#capture_timestamps_ns: is a <class 'torch.Tensor'>, with shape of : torch.Size([1])\n",
      "2024-08-28 18:10:44,267 - INFO - mtd#gravity_in_world: is a <class 'torch.Tensor'>, with shape of : torch.Size([3])\n",
      "2024-08-28 18:10:44,268 - INFO - mtd#ts_world_device: is a <class 'torch.Tensor'>, with shape of : torch.Size([1, 3, 4])\n",
      "2024-08-28 18:10:44,268 - INFO - sequence_name: is a <class 'str'>, value is Apartment_release_golden_skeleton_seq100_10s_sample_M1292\n",
      "2024-08-28 18:10:44,268 - INFO - mfcd#camera-rgb+images: is a <class 'torch.Tensor'>, with shape of : torch.Size([1, 3, 1408, 1408])\n",
      "2024-08-28 18:10:44,269 - INFO - mfcd#camera-slam-left+images: is a <class 'torch.Tensor'>, with shape of : torch.Size([1, 1, 640, 480])\n",
      "2024-08-28 18:10:44,269 - INFO - mfcd#camera-slam-right+images: is a <class 'torch.Tensor'>, with shape of : torch.Size([1, 1, 640, 480])\n"
     ]
    }
   ],
   "source": [
    "# Load Native ATEK WDS data\n",
    "logger.info(\"-------------------- loading ATEK data natively --------------- \")\n",
    "\n",
    "# Loading local WDS files\n",
    "tar_file_urls = [os.path.join(output_wds_path, f\"shards-000{i}.tar\") for i in range(4)]\n",
    "\n",
    "# Batch size is None so that no collation is invoked\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size=None, repeat_flag=False)\n",
    "\n",
    "# Loop over all samples in DataLoader and visualize\n",
    "viz_conf = OmegaConf.load(atek_viz_config_path)\n",
    "atek_visualizer = NativeAtekSampleVisualizer(viz_prefix = \"dataloading_visualizer\", conf = viz_conf)\n",
    "for atek_sample_dict in atek_dataloader:\n",
    "    # First convert it back to ATEK data sample and visualize\n",
    "    atek_sample = create_atek_data_sample_from_flatten_dict(atek_sample_dict)\n",
    "    atek_visualizer.plot_atek_sample(atek_sample)\n",
    "\n",
    "# Print the content of the first sample in the DataLoader\n",
    "logger.info(\"Loading native atek data sample as a Dict, containing the following: \")\n",
    "first_sample = next(iter(atek_dataloader))\n",
    "print_data_sample_dict_content(first_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89075b58-3741-4cd1-9b95-c95e063ca614",
   "metadata": {},
   "source": [
    "## Step 2: load ATEK WDS data as CubeRCNN-type data and print content (using ModelAdaptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d69769-24cd-4f12-8305-8c42aacc0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28 18:12:19,175 - INFO - -------------------- ATEK WDS data can also be loaded as CubeRCNN --------------- \n",
      "2024-08-28 18:12:19,177 - INFO - Loading atek data sample as a CubeRCNN-type data dict, containing the following: \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Only linear camera model supported in CubeRCNN model, this data has CameraModelType.FISHEYE624 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# CubeRCNN's collation function will batch samples directly into list\u001b[39;00m\n\u001b[1;32m      8\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading atek data sample as a CubeRCNN-type data dict, containing the following: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m cubercnn_sample_dict_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcubercnn_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m print_data_sample_dict_content(cubercnn_sample_dict_list[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/atek/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/atek/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/atek/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:41\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/atek/lib/python3.9/site-packages/webdataset/pipeline.py:70\u001b[0m, in \u001b[0;36mDataPipeline.iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an iterator through the entire dataset, using the given number of repetitions.\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepetitions):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator1()\n",
      "File \u001b[0;32m~/miniconda3/envs/atek/lib/python3.9/site-packages/webdataset/filters.py:487\u001b[0m, in \u001b[0;36m_batched\u001b[0;34m(data, batchsize, collation_fn, partial)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create batches of the given size.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m:param data: iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m \n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batchsize:\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m collation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/fbsource/fbcode/surreal/data_services/atek/atek/data_loaders/cubercnn_model_adaptor.py:52\u001b[0m, in \u001b[0;36mCubeRCNNModelAdaptor.atek_to_cubercnn\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m atek_wds_sample \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     51\u001b[0m     sample \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_camera_data_in_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43matek_wds_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_T_world_camera(atek_wds_sample, sample)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Skip if no gt data\u001b[39;00m\n",
      "File \u001b[0;32m~/fbsource/fbcode/surreal/data_services/atek/atek/data_loaders/cubercnn_model_adaptor.py:71\u001b[0m, in \u001b[0;36mCubeRCNNModelAdaptor._update_camera_data_in_sample\u001b[0;34m(self, atek_wds_sample, sample)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# calculate K-matrix\u001b[39;00m\n\u001b[1;32m     70\u001b[0m camera_model \u001b[38;5;241m=\u001b[39m atek_wds_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     72\u001b[0m     camera_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCameraModelType.LINEAR\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly linear camera model supported in CubeRCNN model, this data has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m k_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     75\u001b[0m params \u001b[38;5;241m=\u001b[39m atek_wds_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera_params\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Only linear camera model supported in CubeRCNN model, this data has CameraModelType.FISHEYE624 instead."
     ]
    }
   ],
   "source": [
    "logger.info(\n",
    "    \"-------------------- ATEK WDS data can also be loaded as CubeRCNN --------------- \"\n",
    ")\n",
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 1, repeat_flag = False)\n",
    "\n",
    "\n",
    "# CubeRCNN's collation function will batch samples directly into list\n",
    "logger.info(\"Loading atek data sample as a CubeRCNN-type data dict, containing the following: \")\n",
    "cubercnn_sample_dict_list = next(iter(cubercnn_dataloader))\n",
    "print_data_sample_dict_content(cubercnn_sample_dict_list[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6abc3-2d7a-44e4-b960-36799f273c38",
   "metadata": {},
   "source": [
    "# Example 3: Run Object detection inference using trained CubeRCNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ecfff7-0ece-4749-8953-f8e50d3d1f9b",
   "metadata": {},
   "source": [
    "## Step 1: load trained CubeRCNN model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede944ec-9e4e-47bc-be4b-5920500b6ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "8cca9f3e-a062-4627-9916-8f40d129e10f",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
